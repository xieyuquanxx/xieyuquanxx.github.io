---
title:          "Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts"
date:           2025-06-12 00:01:00 +0800
selected:       true
pub:            "Arxiv"
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Preprint</span>'
pub_date:       "2025"

abstract: >-
  Recently, agents based on multimodal large language models (MLLMs) have achieved remarkable progress across various domains. However, building a generalist agent with capabilities such as perception, planning, action, grounding, and reflection in open-world environments like Minecraft remains challenges: insufficient domain-specific data, interference among heterogeneous tasks, and visual diversity in open-world settings. In this paper, we address these challenges through three key contributions. 1) We propose a knowledge-enhanced data generation pipeline to provide scalable and high-quality training data for agent development. 2) To mitigate interference among heterogeneous tasks, we introduce a Mixture-of-Experts (MoE) architecture with task-level routing. 3) We develop a Multimodal Reasoning-Augmented Reinforcement Learning approach to enhance the agent's reasoning ability for visual diversity in Minecraft. Built upon these innovations, we present Optimus-3, a general-purpose agent for Minecraft. Extensive experimental results demonstrate that Optimus-3 surpasses both generalist multimodal large language models and existing state-of-the-art agents across a wide range of tasks in the Minecraft environment.


# cover:          /assets/images/covers/optimus.png
authors:
  - Zaijing Li
  - <b>Yuquan Xie</b>
  - Rui Shao
  - Gongwei Chen
  - Dongmei Jiang
  - Liqiang Nie
links:
  Paper: https://arxiv.org/abs/2506.10357
  Code: https://github.com/JiuTian-VL/Optimus-3
---
